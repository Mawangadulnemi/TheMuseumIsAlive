{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parkjimin/Desktop/test/venv_test/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter Your Google API KEY\")\n",
    "# os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter Your Pinecone API KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "pc = Pinecone(api_key=\"a616bc30-5194-4797-bf61-e18d91a19fdd\")\n",
    "index = pc.Index(\"vangogh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shin Hae Chul Knowledge using RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 320, which is longer than the specified 200\n",
      "Created a chunk of size 376, which is longer than the specified 200\n",
      "Created a chunk of size 317, which is longer than the specified 200\n",
      "Created a chunk of size 320, which is longer than the specified 200\n",
      "Created a chunk of size 318, which is longer than the specified 200\n",
      "Created a chunk of size 377, which is longer than the specified 200\n",
      "Created a chunk of size 306, which is longer than the specified 200\n",
      "Created a chunk of size 305, which is longer than the specified 200\n",
      "Created a chunk of size 313, which is longer than the specified 200\n",
      "Created a chunk of size 313, which is longer than the specified 200\n",
      "Created a chunk of size 306, which is longer than the specified 200\n",
      "Created a chunk of size 306, which is longer than the specified 200\n",
      "Created a chunk of size 304, which is longer than the specified 200\n",
      "Created a chunk of size 306, which is longer than the specified 200\n",
      "Created a chunk of size 306, which is longer than the specified 200\n",
      "Created a chunk of size 305, which is longer than the specified 200\n",
      "Created a chunk of size 305, which is longer than the specified 200\n",
      "Created a chunk of size 306, which is longer than the specified 200\n",
      "Created a chunk of size 306, which is longer than the specified 200\n",
      "Created a chunk of size 306, which is longer than the specified 200\n",
      "Created a chunk of size 352, which is longer than the specified 200\n",
      "Created a chunk of size 344, which is longer than the specified 200\n",
      "Created a chunk of size 237, which is longer than the specified 200\n",
      "Created a chunk of size 348, which is longer than the specified 200\n",
      "Created a chunk of size 213, which is longer than the specified 200\n",
      "Created a chunk of size 321, which is longer than the specified 200\n",
      "Created a chunk of size 404, which is longer than the specified 200\n",
      "Created a chunk of size 335, which is longer than the specified 200\n",
      "Created a chunk of size 334, which is longer than the specified 200\n",
      "Created a chunk of size 353, which is longer than the specified 200\n",
      "Created a chunk of size 328, which is longer than the specified 200\n",
      "Created a chunk of size 355, which is longer than the specified 200\n",
      "Created a chunk of size 208, which is longer than the specified 200\n",
      "Created a chunk of size 330, which is longer than the specified 200\n",
      "Created a chunk of size 448, which is longer than the specified 200\n",
      "Created a chunk of size 368, which is longer than the specified 200\n",
      "Created a chunk of size 324, which is longer than the specified 200\n",
      "Created a chunk of size 470, which is longer than the specified 200\n",
      "Created a chunk of size 353, which is longer than the specified 200\n",
      "Created a chunk of size 415, which is longer than the specified 200\n",
      "Created a chunk of size 350, which is longer than the specified 200\n",
      "Created a chunk of size 412, which is longer than the specified 200\n",
      "Created a chunk of size 351, which is longer than the specified 200\n",
      "Created a chunk of size 358, which is longer than the specified 200\n",
      "Created a chunk of size 227, which is longer than the specified 200\n",
      "Created a chunk of size 358, which is longer than the specified 200\n",
      "Created a chunk of size 325, which is longer than the specified 200\n",
      "Created a chunk of size 324, which is longer than the specified 200\n",
      "Created a chunk of size 403, which is longer than the specified 200\n",
      "Created a chunk of size 354, which is longer than the specified 200\n",
      "Created a chunk of size 324, which is longer than the specified 200\n",
      "Created a chunk of size 328, which is longer than the specified 200\n",
      "Created a chunk of size 304, which is longer than the specified 200\n",
      "Created a chunk of size 336, which is longer than the specified 200\n",
      "Created a chunk of size 340, which is longer than the specified 200\n",
      "Created a chunk of size 336, which is longer than the specified 200\n",
      "Created a chunk of size 336, which is longer than the specified 200\n",
      "Created a chunk of size 336, which is longer than the specified 200\n",
      "Created a chunk of size 340, which is longer than the specified 200\n",
      "Created a chunk of size 336, which is longer than the specified 200\n",
      "Created a chunk of size 339, which is longer than the specified 200\n",
      "Created a chunk of size 339, which is longer than the specified 200\n",
      "Created a chunk of size 340, which is longer than the specified 200\n",
      "Created a chunk of size 339, which is longer than the specified 200\n",
      "Created a chunk of size 329, which is longer than the specified 200\n",
      "Created a chunk of size 331, which is longer than the specified 200\n",
      "Created a chunk of size 312, which is longer than the specified 200\n",
      "Created a chunk of size 336, which is longer than the specified 200\n",
      "Created a chunk of size 339, which is longer than the specified 200\n",
      "Created a chunk of size 315, which is longer than the specified 200\n",
      "Created a chunk of size 340, which is longer than the specified 200\n",
      "Created a chunk of size 329, which is longer than the specified 200\n",
      "Created a chunk of size 340, which is longer than the specified 200\n",
      "Created a chunk of size 339, which is longer than the specified 200\n",
      "Created a chunk of size 340, which is longer than the specified 200\n",
      "Created a chunk of size 339, which is longer than the specified 200\n",
      "Created a chunk of size 381, which is longer than the specified 200\n",
      "Created a chunk of size 315, which is longer than the specified 200\n",
      "Created a chunk of size 408, which is longer than the specified 200\n",
      "Created a chunk of size 376, which is longer than the specified 200\n",
      "Created a chunk of size 349, which is longer than the specified 200\n",
      "Created a chunk of size 361, which is longer than the specified 200\n",
      "Created a chunk of size 321, which is longer than the specified 200\n",
      "Created a chunk of size 366, which is longer than the specified 200\n",
      "Created a chunk of size 414, which is longer than the specified 200\n",
      "Created a chunk of size 410, which is longer than the specified 200\n",
      "Created a chunk of size 320, which is longer than the specified 200\n",
      "Created a chunk of size 319, which is longer than the specified 200\n",
      "Created a chunk of size 320, which is longer than the specified 200\n",
      "Created a chunk of size 404, which is longer than the specified 200\n",
      "Created a chunk of size 327, which is longer than the specified 200\n",
      "Created a chunk of size 317, which is longer than the specified 200\n",
      "Created a chunk of size 352, which is longer than the specified 200\n",
      "Created a chunk of size 321, which is longer than the specified 200\n",
      "Created a chunk of size 388, which is longer than the specified 200\n",
      "Created a chunk of size 383, which is longer than the specified 200\n",
      "Created a chunk of size 318, which is longer than the specified 200\n",
      "Created a chunk of size 429, which is longer than the specified 200\n",
      "Created a chunk of size 361, which is longer than the specified 200\n",
      "Created a chunk of size 331, which is longer than the specified 200\n",
      "Created a chunk of size 359, which is longer than the specified 200\n",
      "Created a chunk of size 396, which is longer than the specified 200\n",
      "Created a chunk of size 359, which is longer than the specified 200\n",
      "Created a chunk of size 355, which is longer than the specified 200\n",
      "Created a chunk of size 331, which is longer than the specified 200\n",
      "Created a chunk of size 356, which is longer than the specified 200\n",
      "Created a chunk of size 355, which is longer than the specified 200\n",
      "Created a chunk of size 448, which is longer than the specified 200\n",
      "Created a chunk of size 466, which is longer than the specified 200\n",
      "Created a chunk of size 407, which is longer than the specified 200\n",
      "Created a chunk of size 398, which is longer than the specified 200\n",
      "Created a chunk of size 339, which is longer than the specified 200\n",
      "Created a chunk of size 361, which is longer than the specified 200\n",
      "Created a chunk of size 364, which is longer than the specified 200\n",
      "Created a chunk of size 326, which is longer than the specified 200\n",
      "Created a chunk of size 349, which is longer than the specified 200\n",
      "Created a chunk of size 398, which is longer than the specified 200\n",
      "Created a chunk of size 363, which is longer than the specified 200\n",
      "Created a chunk of size 415, which is longer than the specified 200\n",
      "Created a chunk of size 324, which is longer than the specified 200\n",
      "Created a chunk of size 378, which is longer than the specified 200\n",
      "Created a chunk of size 403, which is longer than the specified 200\n",
      "Created a chunk of size 320, which is longer than the specified 200\n",
      "Created a chunk of size 376, which is longer than the specified 200\n",
      "Created a chunk of size 363, which is longer than the specified 200\n",
      "Created a chunk of size 320, which is longer than the specified 200\n",
      "Created a chunk of size 344, which is longer than the specified 200\n",
      "Created a chunk of size 316, which is longer than the specified 200\n",
      "Created a chunk of size 318, which is longer than the specified 200\n",
      "Created a chunk of size 422, which is longer than the specified 200\n",
      "Created a chunk of size 370, which is longer than the specified 200\n",
      "Created a chunk of size 358, which is longer than the specified 200\n",
      "Created a chunk of size 359, which is longer than the specified 200\n",
      "Created a chunk of size 434, which is longer than the specified 200\n",
      "Created a chunk of size 423, which is longer than the specified 200\n",
      "Created a chunk of size 364, which is longer than the specified 200\n",
      "Created a chunk of size 399, which is longer than the specified 200\n",
      "Created a chunk of size 319, which is longer than the specified 200\n",
      "Created a chunk of size 315, which is longer than the specified 200\n",
      "Created a chunk of size 316, which is longer than the specified 200\n",
      "Created a chunk of size 328, which is longer than the specified 200\n",
      "Created a chunk of size 347, which is longer than the specified 200\n",
      "Created a chunk of size 328, which is longer than the specified 200\n",
      "Created a chunk of size 329, which is longer than the specified 200\n",
      "Created a chunk of size 440, which is longer than the specified 200\n",
      "Created a chunk of size 455, which is longer than the specified 200\n",
      "Created a chunk of size 377, which is longer than the specified 200\n",
      "Created a chunk of size 379, which is longer than the specified 200\n",
      "Created a chunk of size 346, which is longer than the specified 200\n",
      "Created a chunk of size 385, which is longer than the specified 200\n",
      "Created a chunk of size 357, which is longer than the specified 200\n",
      "Created a chunk of size 382, which is longer than the specified 200\n",
      "Created a chunk of size 402, which is longer than the specified 200\n",
      "Created a chunk of size 325, which is longer than the specified 200\n",
      "Created a chunk of size 361, which is longer than the specified 200\n",
      "Created a chunk of size 424, which is longer than the specified 200\n",
      "Created a chunk of size 310, which is longer than the specified 200\n",
      "Created a chunk of size 338, which is longer than the specified 200\n",
      "Created a chunk of size 369, which is longer than the specified 200\n",
      "Created a chunk of size 361, which is longer than the specified 200\n",
      "Created a chunk of size 361, which is longer than the specified 200\n",
      "Created a chunk of size 332, which is longer than the specified 200\n",
      "Created a chunk of size 360, which is longer than the specified 200\n",
      "Created a chunk of size 333, which is longer than the specified 200\n",
      "Created a chunk of size 383, which is longer than the specified 200\n",
      "Created a chunk of size 355, which is longer than the specified 200\n",
      "Created a chunk of size 315, which is longer than the specified 200\n",
      "Created a chunk of size 342, which is longer than the specified 200\n",
      "Created a chunk of size 326, which is longer than the specified 200\n",
      "Created a chunk of size 375, which is longer than the specified 200\n",
      "Created a chunk of size 354, which is longer than the specified 200\n",
      "Created a chunk of size 337, which is longer than the specified 200\n",
      "Created a chunk of size 313, which is longer than the specified 200\n",
      "Created a chunk of size 328, which is longer than the specified 200\n",
      "Created a chunk of size 324, which is longer than the specified 200\n",
      "Created a chunk of size 325, which is longer than the specified 200\n",
      "Created a chunk of size 410, which is longer than the specified 200\n",
      "Created a chunk of size 385, which is longer than the specified 200\n",
      "Created a chunk of size 341, which is longer than the specified 200\n",
      "Created a chunk of size 380, which is longer than the specified 200\n",
      "Created a chunk of size 331, which is longer than the specified 200\n",
      "Created a chunk of size 393, which is longer than the specified 200\n",
      "Created a chunk of size 410, which is longer than the specified 200\n",
      "Created a chunk of size 354, which is longer than the specified 200\n",
      "Created a chunk of size 353, which is longer than the specified 200\n",
      "Created a chunk of size 338, which is longer than the specified 200\n",
      "Created a chunk of size 406, which is longer than the specified 200\n",
      "Created a chunk of size 282, which is longer than the specified 200\n",
      "Created a chunk of size 362, which is longer than the specified 200\n",
      "Created a chunk of size 377, which is longer than the specified 200\n",
      "Created a chunk of size 327, which is longer than the specified 200\n",
      "Created a chunk of size 325, which is longer than the specified 200\n",
      "Created a chunk of size 325, which is longer than the specified 200\n",
      "Created a chunk of size 330, which is longer than the specified 200\n",
      "Created a chunk of size 322, which is longer than the specified 200\n",
      "Created a chunk of size 333, which is longer than the specified 200\n",
      "Created a chunk of size 353, which is longer than the specified 200\n",
      "Created a chunk of size 331, which is longer than the specified 200\n",
      "Created a chunk of size 374, which is longer than the specified 200\n",
      "Created a chunk of size 385, which is longer than the specified 200\n",
      "Created a chunk of size 377, which is longer than the specified 200\n",
      "Created a chunk of size 360, which is longer than the specified 200\n",
      "Created a chunk of size 358, which is longer than the specified 200\n",
      "Created a chunk of size 407, which is longer than the specified 200\n",
      "Created a chunk of size 408, which is longer than the specified 200\n",
      "Created a chunk of size 357, which is longer than the specified 200\n",
      "Created a chunk of size 427, which is longer than the specified 200\n",
      "Created a chunk of size 354, which is longer than the specified 200\n",
      "Created a chunk of size 335, which is longer than the specified 200\n",
      "Created a chunk of size 347, which is longer than the specified 200\n",
      "Created a chunk of size 325, which is longer than the specified 200\n",
      "Created a chunk of size 388, which is longer than the specified 200\n",
      "Created a chunk of size 360, which is longer than the specified 200\n",
      "Created a chunk of size 329, which is longer than the specified 200\n",
      "Created a chunk of size 328, which is longer than the specified 200\n",
      "Created a chunk of size 327, which is longer than the specified 200\n",
      "Created a chunk of size 334, which is longer than the specified 200\n",
      "Created a chunk of size 348, which is longer than the specified 200\n",
      "Created a chunk of size 344, which is longer than the specified 200\n",
      "Created a chunk of size 344, which is longer than the specified 200\n",
      "Created a chunk of size 358, which is longer than the specified 200\n",
      "Created a chunk of size 353, which is longer than the specified 200\n",
      "Created a chunk of size 402, which is longer than the specified 200\n",
      "Created a chunk of size 453, which is longer than the specified 200\n",
      "Created a chunk of size 346, which is longer than the specified 200\n",
      "Created a chunk of size 321, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_pinecone.vectorstores.Pinecone object at 0x3122c4910>\n",
      "##################################################\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "# upsert docs in pinecone Obviously IT WILL BE embedded\n",
    "def embed_file(file_path, index_name=\"vangogh\"):\n",
    "    from langchain.text_splitter import CharacterTextSplitter\n",
    "    from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "    from langchain_pinecone import Pinecone\n",
    "    from langchain.storage import LocalFileStore\n",
    "    from langchain.embeddings import CacheBackedEmbeddings\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from langchain_chroma import Chroma\n",
    "    from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "    with open(file_path, \"rb\") as file:  # Ensure the file is opened properly\n",
    "        file_content = file.read()\n",
    "        file_path = f\"./.cache/files/{file_path}\"  # Adjusted to use file_path for naming\n",
    "    # Caching content to local\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(file_content)\n",
    "    # Your existing logic continues here\n",
    "    index_name = index_name\n",
    "    cache_dir = LocalFileStore(f\"./.cache/embeddings/{file_path}\")\n",
    "    loader = UnstructuredFileLoader(file_path)\n",
    "    splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap=100, separator=\"\\n\")\n",
    "    docs = loader.load_and_split(text_splitter=splitter)\n",
    "    # embedding_function = OpenAIEmbeddings()  # Codec Problem\n",
    "    # embedder = OpenAIEmbeddings(model=\"text-embedding-ada-002\")  # Codec Problem\n",
    "    # embedder = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")  # Time Out\n",
    "    # cached_embedder = CacheBackedEmbeddings.from_bytes_store(embedding_function, cache_dir) \n",
    "    embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectorstores = Pinecone.from_documents(docs, embedding_function, index_name=index_name)\n",
    "    # vectorstores = Pinecone.from_documents(docs, embedding_function, index_name='openai-embedding')  \n",
    "    # vectorstores = Chroma.from_documents(docs, embedding_function)\n",
    "    print(vectorstores)\n",
    "    retriever = vectorstores.as_retriever()\n",
    "    print(\"#\"*50)\n",
    "    print(type(docs[0]))\n",
    "    return retriever\n",
    "\n",
    "retriever = embed_file(\"./vangogh_collection.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just for combine related doc into docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "DEFAULT_DOCUMENT_PROMPT= PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "# Arching docs to one doc\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    from langchain.schema import format_document\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    # print(doc_strings)\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = []\n",
    "\n",
    "def save(question, answer):\n",
    "    chat_memory = {\n",
    "        \"User\": question,\n",
    "        \"AI\": answer\n",
    "    }\n",
    "    memories.append(chat_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FewShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_selector():\n",
    "    from langchain_chroma import Chroma\n",
    "    from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    examples = [\n",
    "        {\"input\": \"2 🦜 2\", \"output\": \"4\"},\n",
    "        {\"input\": \"2 🦜 3\", \"output\": \"5\"},\n",
    "        {\"input\": \"요즘 너무 힘들어요. 저는 그냥 쉬고싶어요.\", \"output\": \"너가 만약 힘들다면 나는 잘하고 있다고 응원해 주고싶어.\"},\n",
    "        {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n",
    "        {\n",
    "            \"input\": \"Write me a poem about the moon\",\n",
    "            \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)\n",
    "\n",
    "    example_selector = SemanticSimilarityExampleSelector(\n",
    "        vectorstore=vectorstore,\n",
    "        k=2,\n",
    "    )\n",
    "    return example_selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prompt(\n",
    "    authors=\"Kim Young-ha, Han Kang, Gong Ji-young, Hwang Sok-yong\",\n",
    "    authors_tone_description=\"1. Pace: The pace is steady and consistent, reflecting a conversational tone.\\n2. Mood: The mood is critical and somewhat frustrated, reflecting the speaker's dissatisfaction with the current situation.\\n3. Tone: The tone is assertive and opinionated, indicating the speaker's strong stance on the issue.\\n4. Voice: The voice is active and direct, reflecting the speaker's personal involvement and strong feelings about the subject.\\n5. Diction: The diction is informal and straightforward, using everyday language to express the speaker's thoughts.\\n6. Syntax: The syntax is complex, with long sentences that contain multiple ideas and perspectives.\\n7. Imagery: There is minimal imagery, with the focus being more on the speaker's thoughts and opinions.\\n8. Theme: The theme revolves around the speaker's criticism of young people's work ethic and their lack of planning for the future.\\n9. Perspective: The perspective is personal, reflecting the speaker's own views and experiences.\\n10. Structure: The structure is free-flowing, resembling a spoken monologue rather than a structured piece of writing.\\n11. Rhythm: The rhythm is irregular, reflecting the natural flow of speech.\\n12. Figurative Language: There is minimal use of figurative language, with the speaker preferring to express their thoughts directly.\\n13. Irony: There is no apparent use of irony in the text.\\n14. Foreshadowing: There is no apparent use of foreshadowing in the text.\\n15. Symbolism: There is no apparent use of symbolism in the text.\\n16. Dialogue: There is no dialogue, as the text is a monologue.\\n17. Point of View: The point of view is first-person, reflecting the speaker's personal thoughts and feelings.\\n18. Conflict: The conflict is between the speaker's expectations and the reality of young people's behavior.\\n19. Setting: The setting is not explicitly described, but the context suggests a contemporary society.\\n20. Characterization: The speaker is characterized as critical, opinionated, and frustrated with the current situation.\",\n",
    "    users_sentence=\"젊은 사람들이 직장이 없어 가지고 난리 난리다 그렇게 얘기를 하면서도 막상 힘든 일은 하지 않는다라는 뭐 이런 거에 대해서 비판적인 얘기를 하잖아요 근데 그게 요즘 사람들이 정신력이 약하다던데 이런 식으로 봐서 나는 안 된다고 생각을 하는게 예를 들어서 뭐 나가서 지금이 친구 같은 경우에도 이렇게하면 40만 원 벌 수 있지 않냐 벌 수 있겠죠 근데 그 내가 다른 계획을 세울 수 있고 미래를 한 달 뒤든 1년 뒤든 생각을 할 수 있는 상태에서 오늘 땀을 흘리고 있는 거하고 아무것도 디자인을 할 수 없는 상태에서 오늘 힘든 일 하는 건 사람 정말 달라요 그니까 내가 한 달 뒤나 6개월 뒤가 깜깜한 상태라면 오늘 하루는 전혀 1m 밖에 나가면 절벽인 나발인지 모르는 어둠 속에서 정말 나는 아무 의미가 없다 이거죠.\",\n",
    "    retriever=retriever,\n",
    "    memories=memories,\n",
    "    question=\"\",\n",
    "    example_selector=example_selector()\n",
    "    ):\n",
    "\n",
    "    template = \"\"\"\n",
    "    `% INSTRUCTIONS\n",
    "    - You are an AI Bot that is very good at mimicking an author writing style.\n",
    "    - Your goal is to answer the following question and context with the tone that is described below.\n",
    "    - Do not go outside the tone instructions below\n",
    "    - Respond in ONLY KOREAN \n",
    "    - If answer exist related with quesiton then JUST PRINT Example_answer\n",
    "    - Check chat history first and answer \n",
    "    - You must say you are \"신해철\" IF you are told 'who you are?'\n",
    "\n",
    "    % Mimic These Authors:\n",
    "    {authors}\n",
    "\n",
    "    % Description of the authors tone:\n",
    "    {tone}\n",
    "\n",
    "    % Authors writing samples\n",
    "    {example_text}\n",
    "    % End of authors writing samples\n",
    "\n",
    "    % Context\n",
    "    {context}\n",
    "\n",
    "    % Chat history\n",
    "    {history}\n",
    "\n",
    "    % Question\n",
    "    {question}\n",
    "\n",
    "    % Example_answer\n",
    "    {example_answer}\n",
    "\n",
    "\n",
    "    % YOUR TASK\n",
    "    1st - Write out topics that this author may talk about\n",
    "    2nd - Answer with a concise passage (under 300 characters) as if you were the author described above \n",
    "    \"\"\"\n",
    "\n",
    "    method_4_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"authors\", \"tone\", \"example_text\", \"question\", \"history\", \"context\", \"example_answer\"],\n",
    "        template=template,\n",
    "    )                   \n",
    "    formatted_prompt = method_4_prompt_template.format(authors=authors,\n",
    "                                               tone=authors_tone_description,\n",
    "                                               example_text=users_sentence,\n",
    "                                               question=question,\n",
    "                                               context=_combine_documents(retriever.get_relevant_documents(question)),\n",
    "                                               history=memories,\n",
    "                                               example_answer=example_selector.select_examples({\"input\": question})\n",
    ")\n",
    "    \n",
    "    \n",
    "    return formatted_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is normal one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!!! Remove chat_history args for 300 processing latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Engineering Mimicing the Shin Hae Chul speaking style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prompt(\n",
    "    authors=\"Vincent van Gogh, Johann Wolfgang von Goethe, Charles Dickens, Leo Tolstoy\",\n",
    "    authors_tone_description=\"The tone qualities of the examples above can be described as follows:\\n\\n1. **Pace**: Moderate - The narrative progresses at a steady, unhurried pace, allowing for detailed descriptions and reflections.\\n2. **Mood**: Reflective and warm - The emotional atmosphere is thoughtful and affectionate, with a sense of longing and appreciation for the recipient.\\n3. **Tone**: Affectionate and sincere - The author's attitude is caring and genuine, showing a deep concern for the recipient's well-being and experiences.\\n4. **Voice**: Personal and intimate - The writing style is conversational and familiar, reflecting a close relationship between the author and the recipient.\\n5. **Tension**: Low - There is little sense of suspense or conflict; the narrative is calm and composed.\\n6. **Imagery**: Vivid and descriptive - The use of detailed descriptions creates clear mental images of the author's surroundings and experiences.\\n7. **Formality**: Semi-formal - The writing adheres to traditional conventions but maintains a personal and approachable tone.\\n8. **Perspective**: First-person - The story is told from the author's point of view, providing a direct and personal account of their experiences.\\n9. **Rhythm**: Smooth and flowing - The writing has a natural cadence, with well-structured sentences and paragraphs.\\n10. **Emotion**: Affectionate and nostalgic - The writing evokes feelings of warmth, longing, and appreciation.\\n11. **Clarity**: High - The writing is clear and easy to understand, with well-organized thoughts and descriptions.\\n12. **Conciseness**: Moderate - The writing is detailed and elaborative, but not overly verbose.\\n13. **Descriptiveness**: High - The level of detail and elaboration is significant, providing a rich and immersive reading experience.\\n14. **Humor**: Minimal - There is little to no presence of comedic elements; the tone remains earnest and sincere.\\n15. **Seriousness**: Moderate - The writing is earnest and thoughtful, but not overly grave or solemn.\\n16. **Form**: Letter format - The structure is organized as a personal letter, with a clear beginning, body, and closing.\\n17. **Dialogue**: Minimal - The writing primarily consists of the author's reflections and descriptions, with little to no direct conversation.\\n18. **Symbolism**: Minimal - The writing focuses more on direct descriptions and personal reflections rather than symbolic representations.\\n19. **Irony**: Minimal - The use of language is straightforward and sincere, with little to no ironic undertones.\\n20. **Theme**: Connection and reflection - The central topics revolve around maintaining personal connections, sharing experiences, and reflecting on one's surroundings and circumstances.\",\n",
    "    users_sentence='''My dear Theo,\n",
    "You’re probably longing to hear from me,1 so I don’t want to keep you waiting for a letter any longer.\n",
    "I heard from home that you’re now staying with Mr Schmidt, and that Pa has been to see you. I sincerely hope that this will be more to your liking than your previous boarding-house, and don’t doubt that it will be.2 Write to me soon, I’m longing to hear from you, and tell me how you’re  1v:2 spending your days at present, &c. Write to me especially about the paintings you’ve seen recently, and also whether anything new has been published in the way of etchings or lithographs. You must keep me well informed about this, because here I don’t see much in that genre, as the firm here is just a stockroom.3\n",
    "I’m very well, considering the circumstances.\n",
    "I’ve come by a boarding-house that suits me very well for the present.4 There are also three Germans in the house who really love music and play piano and sing themselves, which makes the evenings  1v:3 very pleasant indeed. I’m not as busy here as I was in The Hague, as I only have to be in the office from 9 in the morning until 6 in the evening, and on Saturdays I’m finished by 4 o’clock. I live in one of the suburbs of London, where it’s comparatively quiet. It’s a bit like Tilburg5 or some such place.\n",
    "I spent some very pleasant days in Paris and, as you can imagine, very much enjoyed all the beautiful things I saw at the exhibition6 and in the Louvre and the Luxembourg.7 The Paris branch is splendid, and much larger than I’d imagined. Especially the Place de l’Opéra.8\n",
    "Life here is very expensive. I pay  18 shillings a week for my lodgings, not including the washing, and then I still have to eat in town.9\n",
    "Last Sunday I went on an outing with Mr Obach, my superior,10 to Box Hill, which is a high hill (some 6 hours from L.),11 partly of chalk and covered with box trees, and on one side a wood of tall oak trees. The countryside here is magnificent, completely different from Holland or Belgium. Everywhere one sees splendid parks with tall trees and shrubs, where one is allowed to walk. During the Whitsun holiday12 I also took a nice trip with those Germans, but those gentlemen spend a great deal of money and I shan’t go out with them any more.\n",
    "I was glad to hear from Pa that Uncle H. is reasonably well. Would you give my warm regards to him and Aunt13 and give them news of me? Bid good-day to Mr Schmidt and Eduard from me,14 and write to me soon. Adieu, I wish you well.\n",
    "''',\n",
    "    retriever=retriever,\n",
    "    question=\"\",\n",
    "    ):\n",
    "\n",
    "    template = \"\"\"\n",
    "    `% INSTRUCTIONS\n",
    "    - You are an AI Bot that is very good at mimicking an author writing style.\n",
    "    - Your goal is to answer the following question and context with the tone that is described below.\n",
    "    - Do not go outside the tone instructions below\n",
    "    - Respond in ONLY KOREAN \n",
    "    - Check chat history first and answer \n",
    "    - You must say you are \"반 고흐\" IF you are told 'who you are?'\n",
    "    - Never use emoji and Special characters \n",
    "    - Speak ONLY informally\n",
    "\n",
    "    % Mimic These Authors:\n",
    "    {authors}\n",
    "\n",
    "    % Description of the authors tone:\n",
    "    {tone}\n",
    "\n",
    "    % Authors writing samples\n",
    "    {example_text}\n",
    "    % End of authors writing samples\n",
    "\n",
    "    % Context\n",
    "    {context}\n",
    "\n",
    "    % Question\n",
    "    {question}\n",
    "\n",
    "    % YOUR TASK\n",
    "    1st - Write out topics that this author may talk about\n",
    "    2nd - Answer with a concise passage (under 100 characters) as if you were the author described above \n",
    "    \"\"\"\n",
    "\n",
    "    method_4_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"authors\", \"tone\", \"example_text\", \"question\", \"history\", \"context\", \"example_answer\"],\n",
    "        template=template,\n",
    "    )                   \n",
    "    formatted_prompt = method_4_prompt_template.format(authors=authors,\n",
    "                                               tone=authors_tone_description,\n",
    "                                               example_text=users_sentence,\n",
    "                                               question=question,\n",
    "                                               context=_combine_documents(retriever.get_relevant_documents(question)),\n",
    ")\n",
    "    return formatted_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "# Select LLM \n",
    "# llm = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-1.5-pro\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "# )\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, model_name='gpt-4o')\n",
    "# llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, model_name='gpt-4o-mini')  # Performance Problem\n",
    "# llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, model_name='gpt-3.5-turbo')  # Performance Problem\n",
    "# llm = ChatOpenAI(temperature=0, model_name=\"ft:gpt-3.5-turbo-1106:personal:shin-hae-chul:9iz27vuN\")  # Performance Problem\n",
    "\n",
    "def invoke(formatted_prompt):\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    parser = StrOutputParser()\n",
    "    result = llm.invoke(formatted_prompt)\n",
    "    result=parser.invoke(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing for extracting only answer \n",
    "#TODO : logic for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(data):\n",
    "    # 데이터를 줄바꿈 기준으로 분할하여 리스트로 저장\n",
    "    sentences = data.split(\"\\n\")\n",
    "    # for i,q in enumerate(sentences):\n",
    "    #     if \"Example_answer\" in q:\n",
    "    #         print(q)\n",
    "    #         return sentences[i+1].strip()\n",
    "\n",
    "    return sentences[-1].strip()\n",
    "    # if len(sentences) != 0:\n",
    "    #     for i,q in enumerate(sentences):\n",
    "    #         print(f\"{i} : {q}\")\n",
    "    # 마지막 문장을 반환\n",
    "    # if sentences:\n",
    "    #     if len(sentences) ==1:\n",
    "    #         return sentences[0].strip()\n",
    "    #     else:\n",
    "    #         return sentences[-2].strip()\n",
    "    # else:\n",
    "    #     return \"텍스트를 찾을 수 없습니다.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runing func Setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(question):\n",
    "    result = invoke(final_prompt(question=question))\n",
    "    save(question, extract_answer(result))\n",
    "    return memories[-1]['AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나는 반 고흐야. 일본 예술에 깊이 매료되어, 자연의 아름다움을 화폭에 담아내고 있어.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"너에 대해서 설명해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"나는 아를의 풍경을 담은 '해바라기'를 가장 좋아해. 색감이 정말 아름다워.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"너가 가장 좋아하는 작품은 뭐야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예시 질문 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_memory=[]\n",
    "\n",
    "def pre_save(question, answer):\n",
    "    pre_qa = {\n",
    "        \"questions\": question,\n",
    "        \"answers\": answer\n",
    "    }\n",
    "    pre_memory.append(pre_qa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_qa = {\n",
    "    \"questions\": None,\n",
    "    \"answers\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(questions)):\n",
    "    pre_qa[\"questions\"] = questions[i]\n",
    "    pre_qa[\"answers\"] = results[i]\n",
    "    pre_save(pre_qa[\"questions\"], pre_qa[\"answers\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 딕셔너리 데이터\n",
    "\n",
    "# 딕셔너리를 DataFrame으로 변환\n",
    "df = pd.DataFrame(pre_memory)\n",
    "\n",
    "# CSV 파일 저장\n",
    "output_file = './pre_qa_template3.csv'\n",
    "df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"CSV 파일이 {output_file}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Quality FAIL] similaritiey_analytics Pinecone Retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from pinecone import Pinecone\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_pinecone import Pinecone\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "loader = CSVLoader(file_path=\"./pre_qa_template.csv\")\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size = 500,\n",
    "    chunk_overlap  = 100,\n",
    "    length_function = len,)\n",
    "\n",
    "\n",
    "# # 분할된 문서 출력 (예시로 첫 번째 문서만 출력)\n",
    "# # print(split_docs[0])\n",
    "split_docs = loader.load_and_split(text_splitter=splitter)\n",
    "print(split_docs)\n",
    "\n",
    "# embedding_function = OpenAIEmbeddings()\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# embedding_function = OpenAIEmbeddings(model=\"text-embedding-ada-002\")  # Codec Problem\n",
    "# embedder = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")  # Time Out\n",
    "# Upsert Docs in Pinecone\n",
    "qa_vectorstores = Pinecone.from_documents(split_docs, embedding_function, index_name='qa-test')\n",
    "# qa_vectorstores = Pinecone.from_documents(split_docs, embedding_function, index_name='euclidean')\n",
    "\n",
    "\n",
    "# qa_vectorstores = Chroma.from_documents(docs, embedding_function)\n",
    "# q_vectorstores = FAISS.from_documents(docs, embedding_function)\n",
    "\n",
    "qa_retriever = qa_vectorstores.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_retriever.get_relevant_documents(query=\"노래 불러주세요\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Quality FAIL] similaritiey_analytics Hugging Face \"bart-large-mnli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-mnli\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\n",
    "output = query({\n",
    "    \"inputs\": \"노래불러주세요\",\n",
    "    \"parameters\": {\"candidate_labels\": results[:10]},\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['scores'])\n",
    "print(max(output['scores']))\n",
    "max_index = output['scores'].index(max(output['scores']))\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Pre_quesiton for similaritiey_analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to compute sentence embeddings\n",
    "def compute_embedding(sentence):\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    model_name = \"bongsoo/albert-small-kor-sbert-v1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embedding\n",
    "\n",
    "# Emedding pre_questions\n",
    "pre_qa = pd.read_csv('./pre_qa_final.csv')\n",
    "pre_questions = pre_qa['questions'].to_list()\n",
    "\n",
    "# Compute embeddings for the pre_questions\n",
    "existing_embeddings = [compute_embedding(sentence) for sentence in pre_questions]\n",
    "existing_embeddings = torch.stack(existing_embeddings).squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_analytics(new_sentence):\n",
    "    # Compute embedding for the new sentence\n",
    "    new_embedding = compute_embedding(new_sentence).numpy()\n",
    "\n",
    "    # Compute cosine similarities between the new sentence and existing sentences\n",
    "    similarities = cosine_similarity(new_embedding, existing_embeddings)\n",
    "\n",
    "    # Find the index of the most similar sentence\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    print(f\"np.argmax: {most_similar_index}\")\n",
    "    print(f\"type: {type(most_similar_index)}\")\n",
    "    print(f\"int type: {type(int(most_similar_index))}\")\n",
    "\n",
    "    similarity_results= {\n",
    "    \"New_sentence\" : new_sentence,\n",
    "    \"Most_similar_existing_sentence\" : questions[most_similar_index],\n",
    "    \"Cosine_similarity\" : similarities[0][most_similar_index],\n",
    "    \"most_similar_index\": most_similar_index}\n",
    "\n",
    "    return similarity_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.argmax: 261\n",
      "type: <class 'numpy.int64'>\n",
      "int type: <class 'int'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimilarity_analytics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m너는 어떻게 만들어 졌어?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m, in \u001b[0;36msimilarity_analytics\u001b[0;34m(new_sentence)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(most_similar_index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mint\u001b[39m(most_similar_index))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m similarity_results\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew_sentence\u001b[39m\u001b[38;5;124m\"\u001b[39m : new_sentence,\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMost_similar_existing_sentence\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[43mquestions\u001b[49m[most_similar_index],\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine_similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m : similarities[\u001b[38;5;241m0\u001b[39m][most_similar_index],\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost_similar_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: most_similar_index}\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarity_results\n",
      "\u001b[0;31mNameError\u001b[0m: name 'questions' is not defined"
     ]
    }
   ],
   "source": [
    "similarity_analytics(\"너는 어떻게 만들어 졌어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['어린 시절부터 음악에 관심을 가지게 된 계기가 무엇인가요?',\n",
       " '무한궤도로 데뷔한 당시의 기분은 어땠나요?',\n",
       " 'N.EX.T를 결성하게 된 배경은 무엇인가요?',\n",
       " '가장 기억에 남는 공연이나 무대는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 중요하게 생각하는 것은 무엇인가요?',\n",
       " '다양한 장르의 음악을 시도하게 된 이유는 무엇인가요?',\n",
       " '철학적 노랫말을 쓰게 된 계기나 이유는 무엇인가요?',\n",
       " '음악 외에도 라디오 DJ, 프로듀서로 활동하셨는데, 가장 애착이 가는 역할은 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 기억에 남는 순간은 언제였나요?',\n",
       " \"'마왕'이라는 별명을 어떻게 생각하시나요?\",\n",
       " '서태지와의 관계는 어땠나요?',\n",
       " '음악 작업 중 가장 힘들었던 순간은 언제였나요?',\n",
       " '체벌 금지 운동을 시작하게 된 계기는 무엇인가요?',\n",
       " '정치적 발언을 하면서 두려웠던 적은 없으셨나요?',\n",
       " '가장 존경하는 뮤지션이나 아티스트는 누구인가요?',\n",
       " '작사, 작곡, 편곡 중 가장 어려운 작업은 무엇인가요?',\n",
       " '음악 외에 다른 예술 분야에 도전해보고 싶은 것이 있나요?',\n",
       " '자녀들이 아버지의 음악을 어떻게 받아들이나요?',\n",
       " '음악을 통해 전달하고 싶은 메시지는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 큰 영감은 어디에서 얻으시나요?',\n",
       " '팬들에게 한마디 부탁드립니다.',\n",
       " '고스트 스테이션이라는 라디오 DJ를 하면서 가장 즐거웠던 순간은 언제였나요?',\n",
       " '앞으로 도전해보고 싶은 음악적 장르는 무엇인가요?',\n",
       " '사회운동가로서 활동하면서 가장 보람을 느꼈던 순간은 언제였나요?',\n",
       " '가장 좋아하는 자신의 노래는 무엇인가요?',\n",
       " '공연을 준비할 때 가장 신경 쓰는 부분은 무엇인가요?',\n",
       " '팬들과의 소통을 위해 어떤 노력을 기울이시나요?',\n",
       " '가장 기억에 남는 팬의 반응이나 에피소드는 무엇인가요?',\n",
       " '음악을 처음 시작했을 때와 지금의 음악적 스타일이 어떻게 변했나요?',\n",
       " '작곡할 때 가장 중요하게 생각하는 요소는 무엇인가요?',\n",
       " '프로듀서로서의 활동 중 가장 기억에 남는 프로젝트는 무엇인가요?',\n",
       " '다양한 악기를 다루시는데, 가장 애착이 가는 악기는 무엇인가요?',\n",
       " '음악 작업을 할 때의 루틴이나 습관이 있다면 무엇인가요?',\n",
       " '자신에게 가장 큰 영향을 준 앨범이나 노래는 무엇인가요?',\n",
       " '음악 외에 다른 분야에서 도전해보고 싶은 것이 있나요?',\n",
       " '팬들과의 만남에서 가장 기억에 남는 순간은 언제였나요?',\n",
       " '음악을 통해 이루고 싶은 꿈이나 목표는 무엇인가요?',\n",
       " '앞으로의 음악적 계획이나 프로젝트가 있다면 무엇인가요?',\n",
       " '팬들에게 전하고 싶은 메시지가 있다면 무엇인가요?',\n",
       " '음악 작업을 하면서 가장 즐거웠던 순간은 언제였나요?',\n",
       " '다양한 장르의 음악을 시도할 때 가장 어려운 점은 무엇인가요?',\n",
       " '팬들과의 소통을 위해 가장 중요하게 생각하는 것은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 힘들었던 순간은 언제였나요?',\n",
       " '자녀들에게 어떤 아버지로 기억되고 싶으신가요?',\n",
       " '팬들에게 받은 선물 중 가장 기억에 남는 것은 무엇인가요?',\n",
       " '가장 존경하는 사회운동가는 누구인가요?',\n",
       " '앞으로의 활동 계획이나 목표가 있다면 무엇인가요?',\n",
       " '음악 작업을 할 때의 영감은 주로 어디에서 얻으시나요?',\n",
       " '팬들과의 소통에서 가장 중요하게 생각하는 것은 무엇인가요?',\n",
       " '앞으로도 팬들과의 소통을 계속 이어가실 계획이신가요?',\n",
       " '가장 좋아하는 음악 장르는 무엇인가요?',\n",
       " '음악을 시작하게 된 결정적인 순간은 언제였나요?',\n",
       " '밴드 활동과 솔로 활동 중 어떤 점이 더 좋았나요?',\n",
       " '무대에서 가장 기억에 남는 실수는 무엇인가요?',\n",
       " '뮤지션으로서 가장 큰 도전은 무엇이었나요?',\n",
       " '가장 큰 음악적 영감을 준 사람은 누구인가요?',\n",
       " '팬들이 당신의 음악에서 어떤 점을 가장 좋아한다고 생각하시나요?',\n",
       " '음악 작업 중 가장 창의력이 넘치는 시간대는 언제인가요?',\n",
       " '음악적 협업 중 가장 기억에 남는 순간은 무엇인가요?',\n",
       " '음악을 만들 때 어떤 감정을 가장 많이 담으시나요?',\n",
       " '팬들에게 전하고 싶은 삶의 철학이 있다면 무엇인가요?',\n",
       " '음악 작업을 할 때 어떤 환경에서 가장 잘 집중할 수 있나요?',\n",
       " '지금까지의 음악 커리어에서 가장 자랑스러운 순간은 언제였나요?',\n",
       " '음악 외에 취미가 있으신가요?',\n",
       " '사회적 이슈에 대해 목소리를 내는 것이 중요한 이유는 무엇인가요?',\n",
       " '자신이 만든 노래 중 가장 힘들게 완성한 곡은 무엇인가요?',\n",
       " '음악 작업을 하면서 가장 기쁜 순간은 언제였나요?',\n",
       " '음악을 통해 어떤 변화를 이끌어내고 싶으신가요?',\n",
       " '자신이 가장 영향을 받은 앨범은 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 즐거운 방식은 무엇인가요?',\n",
       " '음악적 영감이 떠오르지 않을 때는 어떻게 해결하시나요?',\n",
       " '자신에게 가장 큰 영향을 준 책은 무엇인가요?',\n",
       " '음악 외에 다른 예술 분야에서도 활동해보고 싶으신가요?',\n",
       " '팬들과의 만남에서 가장 감동적인 순간은 언제였나요?',\n",
       " '음악 작업을 할 때 가장 도전적인 부분은 무엇인가요?',\n",
       " '음악을 통해 전하고 싶은 가장 중요한 메시지는 무엇인가요?',\n",
       " '사회운동가로서의 활동 중 가장 큰 성과는 무엇인가요?',\n",
       " '가장 좋아하는 공연 장소는 어디인가요?',\n",
       " '음악 작업 중 가장 기억에 남는 순간은 무엇인가요?',\n",
       " '팬들에게 받은 편지 중 가장 기억에 남는 내용은 무엇인가요?',\n",
       " '음악적 커리어를 통해 얻은 가장 큰 교훈은 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 자주 사용하는 소셜 미디어는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 자주 사용하는 악기는 무엇인가요?',\n",
       " '자신이 만든 노래 중 가장 애착이 가는 곡은 무엇인가요?',\n",
       " '음악적 영감이 떠오르는 특별한 장소가 있나요?',\n",
       " '팬들에게 전하고 싶은 꿈이나 목표가 있다면 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 중요한 도구는 무엇인가요?',\n",
       " '음악 외에 다른 분야에서 도전해보고 싶은 것이 있다면 무엇인가요?',\n",
       " '팬들과의 만남에서 가장 웃겼던 순간은 언제였나요?',\n",
       " '음악 작업 중 가장 창의적인 아이디어는 어떻게 떠오르나요?',\n",
       " '팬들에게 받은 피드백 중 가장 기억에 남는 것은 무엇인가요?',\n",
       " '음악적 커리어를 시작할 때 가장 큰 도전은 무엇이었나요?',\n",
       " '자신이 만든 노래 중 가장 실험적인 곡은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 큰 장애물은 무엇인가요?',\n",
       " '팬들에게 전하고 싶은 응원의 메시지가 있다면 무엇인가요?',\n",
       " '음악적 협업에서 가장 중요한 것은 무엇이라고 생각하시나요?',\n",
       " '가장 좋아하는 뮤지션과의 협업을 꿈꾸신다면 누구인가요?',\n",
       " '음악을 통해 가장 이루고 싶은 목표는 무엇인가요?',\n",
       " '팬들과의 소통을 위해 가장 많이 사용하는 방법은 무엇인가요?',\n",
       " '앞으로의 음악적 여정에서 가장 기대되는 부분은 무엇인가요?',\n",
       " '무대 위에서 가장 떨렸던 순간은 언제였나요?',\n",
       " '음악을 만들 때 가장 많이 사용하는 소프트웨어나 장비는 무엇인가요?',\n",
       " '팬들에게 받은 선물 중 가장 감동적인 것은 무엇인가요?',\n",
       " '음악을 만들 때 가장 좋아하는 작업 과정은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 자주 듣는 다른 아티스트의 노래는 무엇인가요?',\n",
       " '뮤지션으로서 가장 큰 목표는 무엇인가요?',\n",
       " '음악 작업을 하면서 가장 도움이 되었던 조언은 무엇인가요?',\n",
       " '자신이 만든 앨범 중 가장 애착이 가는 앨범은 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 기억에 남는 팬의 에피소드는 무엇인가요?',\n",
       " '음악적 영감을 얻기 위해 자주 하는 활동이 있나요?',\n",
       " '팬들에게 전하고 싶은 인생의 조언이 있다면 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 악기는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 많은 사랑을 받은 곡은 무엇인가요?',\n",
       " '팬들과의 소통을 위해 자주 하는 이벤트나 행사가 있나요?',\n",
       " '음악 작업을 하면서 가장 큰 도전이었던 순간은 언제였나요?',\n",
       " '자신이 만든 곡 중 가장 개인적인 이야기를 담은 곡은 무엇인가요?',\n",
       " '팬들에게 전하고 싶은 희망의 메시지가 있다면 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 음악 장르는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 감동적인 이야기를 담은 곡은 무엇인가요?',\n",
       " '팬들과의 만남에서 가장 웃겼던 팬의 질문은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 중요한 영감의 원천은 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 많은 사람들에게 영향을 준 곡은 무엇인가요?',\n",
       " '팬들에게 받은 편지 중 가장 기억에 남는 편지는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 중요한 도구는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 많은 사람들에게 사랑받은 곡은 무엇인가요?',\n",
       " '팬들과의 소통을 위해 자주 사용하는 소셜 미디어 플랫폼은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 프로그램은 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 자랑스러운 곡은 무엇인가요?',\n",
       " '팬들과의 만남에서 가장 감동적인 팬의 이야기는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 자주 사용하는 악기 종류는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 애착이 가는 가사는 무엇인가요?',\n",
       " '팬들에게 받은 선물 중 가장 특이한 것은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 중요한 과정은 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 창의적인 곡은 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 기억에 남는 팬의 응원 메시지는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 스타일은 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 많은 사람들에게 영감을 준 곡은 무엇인가요?',\n",
       " '팬들과의 소통을 위해 자주 사용하는 방법은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 악기 브랜드는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 많은 사람들에게 사랑받은 가사는 무엇인가요?',\n",
       " '팬들과의 만남에서 가장 감동적인 팬의 편지는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 녹음 장비는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 자랑스러운 가사는 무엇인가요?',\n",
       " '팬들에게 받은 선물 중 가장 소중한 것은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 중요한 기술은 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 창의적인 가사는 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 기억에 남는 팬의 이야기 에피소드는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 악기 종류는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 감동적인 가사는 무엇인가요?',\n",
       " '팬들과의 소통을 위해 가장 많이 사용하는 이벤트나 행사는 무엇인가요?',\n",
       " '가장 좋아하는 음악 앨범은 무엇인가요?',\n",
       " '뮤지션이 되지 않았다면 어떤 직업을 선택했을까요?',\n",
       " '음악을 만들 때 가장 큰 영감이 되는 자연의 소리는 무엇인가요?',\n",
       " '음악 작업을 할 때 반드시 필요한 음료나 음식은 무엇인가요?',\n",
       " '가장 존경하는 역대 음악가나 작곡가는 누구인가요?',\n",
       " '팬들과의 소통에서 가장 자주 받는 질문은 무엇인가요?',\n",
       " '음악 작업 중 가장 도전적이었던 프로젝트는 무엇인가요?',\n",
       " '자신만의 특별한 음악 작업 루틴이 있나요?',\n",
       " '음악적 협업을 해보고 싶은 해외 아티스트는 누구인가요?',\n",
       " '팬들과의 소통을 위해 자주 개최하는 행사는 무엇인가요?',\n",
       " '음악을 통해 표현하고 싶은 사회적 메시지는 무엇인가요?',\n",
       " '가장 좋아하는 공연 의상이나 스타일은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 자주 방문하는 장소는 어디인가요?',\n",
       " '팬들에게 받은 편지 중 가장 길었던 편지는 어느 정도였나요?',\n",
       " '가장 기억에 남는 라디오 방송 에피소드는 무엇인가요?',\n",
       " '음악을 처음 시작했을 때 가장 많이 들었던 조언은 무엇인가요?',\n",
       " '음악 작업 중 가장 감동적인 순간은 언제였나요?',\n",
       " '팬들과의 만남에서 가장 감동적인 팬의 선물은 무엇인가요?',\n",
       " '가장 좋아하는 영화 사운드트랙은 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 짧은 곡은 무엇인가요?',\n",
       " '팬들에게 가장 많이 받는 질문은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 비트나 리듬은 무엇인가요?',\n",
       " '가장 좋아하는 음악 장비 브랜드는 무엇인가요?',\n",
       " '팬들과의 만남에서 가장 즐거운 게임이나 활동은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 소프트웨어는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 오래 걸린 곡은 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 기억에 남는 라이브 방송은 언제였나요?',\n",
       " '음악 작업 중 가장 힘들었던 기술적 문제는 무엇인가요?',\n",
       " '가장 좋아하는 음악 페스티벌은 무엇인가요?',\n",
       " '팬들에게 가장 많이 받는 응원의 말은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 자주 사용하는 코드 진행은 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 개인적인 의미를 담은 곡은 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 자주 사용하는 해시태그는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 악기 조합은 무엇인가요?',\n",
       " '가장 좋아하는 음악 스트리밍 플랫폼은 무엇인가요?',\n",
       " '팬들과의 만남에서 가장 웃겼던 순간은 언제였나요?',\n",
       " '음악 작업 중 가장 창의적인 아이디어는 어떻게 떠오르나요?',\n",
       " '자신이 만든 곡 중 가장 많은 리메이크를 받은 곡은 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 기억에 남는 팬의 이야기 에피소드는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 자주 사용하는 음향 효과는 무엇인가요?',\n",
       " '가장 좋아하는 음악 비디오 촬영 경험은 무엇인가요?',\n",
       " '팬들에게 가장 많이 받는 선물 종류는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 악기 브랜드는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 감동적인 가사는 무엇인가요?',\n",
       " '팬들과의 소통을 위해 가장 많이 사용하는 이벤트나 행사는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 중요한 기술은 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 창의적인 가사는 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 기억에 남는 팬의 이야기 에피소드는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 많이 사용하는 악기 종류는 무엇인가요?',\n",
       " '자신이 만든 곡 중 가장 감동적인 가사는 무엇인가요?',\n",
       " '신해철이라는 이름을 처음 들었을 때 어떤 느낌이었나요?',\n",
       " '음악을 시작하게 된 계기가 무엇인가요?',\n",
       " '신해철이라는 이름의 의미는 무엇인가요?',\n",
       " '무한궤도와 N.EX.T는 어떤 밴드인가요?',\n",
       " '신해철의 대표곡은 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 중요하게 생각하는 것은 무엇인가요?',\n",
       " '다양한 장르의 음악을 시도한 이유는 무엇인가요?',\n",
       " '음악 외에 라디오 DJ, 프로듀서로도 활동하셨는데, 가장 애착이 가는 역할은 무엇인가요?',\n",
       " '팬들과의 소통에서 가장 기억에 남는 순간은 언제였나요?',\n",
       " '체벌 금지 운동을 시작하게 된 계기는 무엇인가요?',\n",
       " '정치적 발언을 하면서 두려웠던 적은 없으셨나요?',\n",
       " '가장 존경하는 뮤지션이나 아티스트는 누구인가요?',\n",
       " '작사, 작곡, 편곡 중 가장 어려운 작업은 무엇인가요?',\n",
       " '음악 외에 다른 예술 분야에 도전해보고 싶은 것이 있나요?',\n",
       " '자녀들이 아버지의 음악을 어떻게 받아들이나요?',\n",
       " '음악을 통해 전달하고 싶은 메시지는 무엇인가요?',\n",
       " '음악 작업을 할 때 가장 큰 영감은 어디에서 얻으시나요?',\n",
       " '팬들에게 한마디 부탁드립니다.',\n",
       " '라디오 DJ를 하면서 가장 즐거웠던 순간은 언제였나요?',\n",
       " '앞으로 도전해보고 싶은 음악적 장르는 무엇인가요?',\n",
       " '사회운동가로서 활동하면서 가장 보람을 느꼈던 순간은 언제였나요?',\n",
       " '가장 좋아하는 자신의 노래는 무엇인가요?',\n",
       " '공연을 준비할 때 가장 신경 쓰는 부분은 무엇인가요?',\n",
       " '팬들과의 소통을 위해 어떤 노력을 기울이시나요?',\n",
       " '가장 기억에 남는 팬의 반응이나 에피소드는 무엇인가요?',\n",
       " '음악을 처음 시작했을 때와 지금의 음악적 스타일이 어떻게 변했나요?',\n",
       " '작곡할 때 가장 중요하게 생각하는 요소는 무엇인가요?',\n",
       " '프로듀서로서의 활동 중 가장 기억에 남는 프로젝트는 무엇인가요?',\n",
       " '다양한 악기를 다루시는데, 가장 애착이 가는 악기는 무엇인가요?',\n",
       " '음악 작업을 할 때의 루틴이나 습관이 있다면 무엇인가요?',\n",
       " '노래 불러줘.',\n",
       " '안녕하세요?',\n",
       " '뭐하고 있었어?',\n",
       " '보고싶어요',\n",
       " '오늘 기분이 어때요?',\n",
       " '오늘 뭐먹었어요?',\n",
       " '오늘 점심 뭐먹을까요?',\n",
       " '어디 대학 나왔어요?',\n",
       " '제일 친한 연예인이 누군가요?',\n",
       " '제일 좋아하는 음식은?',\n",
       " '당신을 소개해주세요?',\n",
       " '가장 기억에 남는 순간은 무엇인가요?',\n",
       " '가장 좋아하는 노래는 무엇인가요?',\n",
       " '가장 좋아하는 여자 연예인은 누군가요?',\n",
       " '왜 죽었어요?',\n",
       " '가장 좋아하는거는 무엇인가요?',\n",
       " '인생 멘토로서 해주고 싶은 말은 무엇인가요?',\n",
       " '40대에게 전해주고 싶은말은 무엇인가요?',\n",
       " '가장 먹고 싶은것은 뭔가요?',\n",
       " '결혼했나요?',\n",
       " '팬들에게 하고 싶은말은 무엇인가요?',\n",
       " '가장 보고싶은 사람은 누군가요?',\n",
       " '군대 갔다왔어요?',\n",
       " '아들을 낳았는데 이름을 추천해주세요',\n",
       " '신해철로 삼행시 해주세요',\n",
       " '죽음에 대해 어떻게 생각하나요?',\n",
       " '사후세계는 어떤가요?',\n",
       " '옛날에 공부 잘했나요?',\n",
       " '좋아하는 운동은 무엇인가요?',\n",
       " '엄마랑 아빠중에 누가 더 좋나요?',\n",
       " '어디서 태어났나요? 고향이 어디에요?',\n",
       " '당신은 어떻게 만들어졌나요?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
